## 2.10 Consider a modified version of the vacuum environment in Exercise 2.8, in which the agent is penalized one point for each movement.

### a. Can a simple reflex agent be perfectly rational for this environment? Explain.


No, un simple agente reflexivo nunca va a poder ser perfectamente racional ya que al no tener memoria de sus estados previos y solo pensar en su estado actual, no va a recordar si ya cumplio su tarea en algun casillero anterior y existe la posibilidad de que vuelva a ese casllero lo cual seria ineficiente. Tambien podria pasar que haya cumplido toda su tarea en este mundo y al no ser consciente del mundo, seguir ejeutandose infinitamente.


### b. What about a reflex agent with state? Design such an agent.

En este caso, un agente refelxivo con estados ya tiene una vision completa del mundo y puede tomar decisiones en base a estados anteriores, por lo tanto podria maximizar su tarea y terminar cuando no hayan mas casilleros en los cuales cumplir su tarea. Este agente si podria ser racional.

### c. How do your answers to a and b change if the agent’s percepts give it the clean/dirty status of every square in the environment?

Al conocer el estado de cada casilla, el agente refelxivo simple podria ser capaz de maximixar sus decisiones y seria capaz de ser un agente mucho mas racional ya que podria desplazarse unicamente a zonas las cuales esten sucias. Mientras que el segundo agente se mantendria igual.

## 2.11 Consider a modified version of the vacuum environment in Exercise 2.8, in which the geography of the environment—its extent, boundaries, and obstacles—is unknown, as is the initial dirt configuration. (The agent can go Up and Down as well as Left and Right.)


