Ejericio 1

Primera Parte

Inteligencia artificial débil


Un conjunto de personas cuestiona y cree que una IA es capaz de actuar como un humano, ya que se piensa que “Cada aspecto del aprendizaje o cualquier otra característica de la inteligencia puede describirse con tanta precisión que se puede hacer que una máquina lo simule”.

Se debatió la posibilidad sobre si las máquinas piensan, pero se llegó a la conclusión de que es más útil preguntarse si una máquina puede superar una prueba de inteligencia, la cual se llamó prueba de Turing. La prueba consiste en que un programa debe mantener una conversación (por mensajes en línea) con una persona durante 5 minutos. Luego la persona debe adivinar si la conversación fue con una persona o una máquina (se pasaba la prueba si la máquina podía engañar a la persona un 30% de las veces). Se creía que en el año 2000 esto iba a ser posible, pero no fue así.

Se creó un argumento de la “incapacidad” diciendo que las maquinas nunca iban a ser capaces de: cometer errores, enamorar a alguien, aprender de la experiencia, etc. Sin embargo, se demostró que si son capaces de estas cosas y muchas más, ej.: pueden jugar ajedrez y aprender de los malos movimientos cometidos. Las maquinas con capaces incluso de hacer algunas cosas de mejor maneras y más eficientemente que los humanos. Por otro lado, también hay muchas tareas que las máquinas no pueden hacer, ej.: prueba de Turing.

Si bien hay algunas conjeturas que las máquinas no pueden responder y por eso se las clasifico como inferiores, también hay algunas conjeturas que el ser humano no puede resolver (ej.: problema del mapa de los cuatro colores) y no por eso nos consideramos inferiores a las máquinas.

También Turing desarrollo una teoría en la cual decía que “el comportamiento humano es demasiado complejo para ser capturado por un conjunto de reglas” y dado que las máquinas no pueden hacer más que seguir un conjunto de reglas, no pueden generar un comportamiento tan inteligente como el de los humanos.

Algo que viene a desmentir el pensamiento de que las maquinas solo siguen reglas son las redes neuronales, las cual a partir de reglas pueden generar pensamientos y tomar decisiones. 2 filósofos debaten que las redes neuronales siguen sin parecerse a los humanos debido a estos 4 puntos:

1— Una generalización a partir de ejemplos no puede lograrse sin conocimientos previos, sin embargo, las redes neuronales son capaces de registrar y almacenar conocimientos previos.

2— El aprendizaje de redes neuronales es supervisado, sin embargo, también puede no ser supervisado.

3— Los algoritmos de aprendizaje no funcionan bien con características cambiantes y grandes cantidades, sin embargo, actualmente sí funcionan bien en ambos casos.

4— El cerebro es capaz de dirigir sus sensores para buscar la información correcta, din embargo, la teoría del valor de la información se encarga de dirigir los sensores, por ejemplo robots.



Inteligencia artificial fuerte

Muchos filosofos afirman que aunque una maquina pase la prueba de Turing, serian incapaces de pensar de verdad.

si una máquina que pasa la Prueba de Turing realmente pensaría o simplemente simularía el pensamiento. Turing anticipó esta objeción y se refirió a ella como el "argumento de la conciencia". Se plantea la cuestión de si una máquina debe ser consciente de sus propios estados mentales y emociones, y si debe tener la capacidad de sentir emociones.

Turing Comparó esta situación con la cortesía de asumir que todos piensan en la vida cotidiana. Tambien sugirió que, a medida que las máquinas se vuelvan más sofisticadas, la distinción entre pensamiento "real" y "artificial" podría desaparecer.

Se habla sobre los estados mentales y el cerebro desde una perspectiva fisicalista. Los estados mentales, como creer o saber, se relacionan con el mundo exterior y se supone que están determinados por los estados cerebrales. Sin embargo, se presenta un experimento mental en el que el cerebro de una persona se coloca en una cuba que simula una vida completa, incluida la interacción con el mundo y las experiencias como comer hamburguesas. A pesar de que el estado cerebral es idéntico al de alguien que está comiendo una hamburguesa real, se argumenta que no tendría el estado mental correspondiente, ya que no está experimentando realmente esas situaciones.

La solución propuesta es distinguir entre el "contenido amplio" y el "contenido estrecho" de los estados mentales. El contenido amplio considera tanto el estado cerebral como el entorno en su interpretación, mientras que el contenido estrecho solo se basa en el estado cerebral. El contenido amplio es útil para comprender y predecir el comportamiento de otros, mientras que el contenido estrecho es más relevante para evaluar si los sistemas de inteligencia artificial realmente piensan y tienen estados mentales.

El funcionalismo sostiene que los estados mentales son condiciones causales intermedias entre la entrada y la salida de un sistema. Según esta teoría, dos sistemas con procesos causales isomórficos tendrían los mismos estados mentales. Un experimento mental llamado "experimento de sustitución del cerebro" ilustra esta idea. En este experimento, se imagina un escenario donde el cerebro humano es reemplazado gradualmente por dispositivos electrónicos mientras el comportamiento externo del sujeto permanece inalterado. El debate surge entre si la conciencia también se mantendría o desaparecería durante este proceso. Mientras algunos, creen que la conciencia persistiría, otros,argumentan que se perdería.

os estados mentales no pueden ser completamente explicados por procesos puramente sintácticos, como sugiere el funcionalismo. La semántica y la sintaxis son insuficientes para explicar la mente y que la conciencia es producto de propiedades causales específicas de las neuronas en el cerebro humano. Se usa el "Experimento de la Habitación China". En este escenario imaginario, una persona dentro de una habitación recibe símbolos en chino a través de una abertura y sigue instrucciones de un libro de reglas en inglés para producir respuestas en chino. A pesar de que el sistema parece comprender y generar respuestas en chino, se argumenta que ni la persona ni los elementos en la habitación entienden realmente el chino. Desde esta perspectiva, se sostiene que la ejecución de programas no es suficiente para la comprensión real. Se crean 4 axiomas a partir de este experimento:

1.Los programas informáticos son formales (sintácticos).
    
 2.Las mentes humanas tienen contenidos mentales (semántica).
    
3.La sintaxis por sí misma no es suficiente para la semántica.
    
4.Los cerebros causan mentes.
Se concluye que la ejecución de programas no es suficiente para generar mentes. Su argumento se basa en la idea de que los programas sintácticos no son equivalentes a la semántica y que la comprensión genuina requiere poderes causales específicos, como los que poseen las neuronas en el cerebro humano. No obstante, este enfoque también ha sido objeto de críticas y debates. Algunos argumentan que las intuiciones sobre la comprensión y la conciencia en este contexto pueden ser subjetivas y cuestionables. 

se discuten las cuestiones relacionadas con la conciencia y los "qualia". La conciencia es un aspecto clave de la mente humana que plantea preguntas fundamentales sobre cómo se relaciona con la IA.

La conciencia se refiere a la experiencia subjetiva y consciente de la realidad. Un aspecto particular de la conciencia es lo que se conoce como "qualia", que son las experiencias subjetivas o sensaciones internas que acompañan a los estados mentales.

Se usa el experimento del "espectro invertido" que ilustra cómo los qualia pueden ser diferentes entre individuos mientras mantienen un comportamiento similar. En este experimento, se plantea la posibilidad de que dos personas vean los colores de manera invertida en comparación con el resto de la población. Aunque sus comportamientos y lenguaje se mantienen igual, sus experiencias subjetivas son diferentes.


La discusión sobre la conciencia y los qualia en el contexto de la IA fuerte es relevante porque plantea la pregunta de si las máquinas pueden desarrollar experiencias subjetivas similares a los humanos.


La ética y los riesgos de desarrollar inteligencia artificial

Aquí se plantea si realmente debemos plantearnos desarrollar las IA, ya que quizás es más probable que los efectos negativos sean mayores que los positivos y no los sepamos. Muchas nuevas tecnologías han causado problemas con por ej.: la fisión nuclear en Chernóbil.

Los principales problemas que plantea son:

• La gente podría perder su trabajo por la automatización.

Se cree que se han perdido trabajos gracias a las IA, pero es lo contrario, el desarrollo de las IA ha creado más puestos de los que ha eliminado, y ha creado empleos más interesantes y mejor pagados. La idea no es que las IA remplacen a los humanos, sino que los ayuden en sus tareas.


• La gente puede tener demasiado (o demasiado poco) tiempo libre.

Se creía que esto sucedería, pero es lo contrario, las horas de trabajo han aumentado y los rubros de empleo con todas las nuevas tecnologías también lo han hecho.
La IA aumenta el ritmo de innovación tecnológica y, por tanto, contribuye a trabajar más, pero también ayuda a que los agentes se encarguen de ciertas tareas para que los humanos tengamos tiempo libre.

• La gente podría perder su sentido de ser única.

Se creía que los humanos se convertirían en autómatas, una idea que se traduce en la perdida de autonomía o de humanidad. La humanidad ya ha vivido otras revoluciones, se compara la supuesta amenaza de la IA en este siglo con la supuesta amenaza de la teoría de evolución de Darwin para las personas del siglo XIX.


• Los sistemas de IA podrían utilizarse con fines indeseables.

Se cree que las tecnologías avanzadas han sido usadas por los poderosos para suprimir a sus rivales. Se dice que: “Una ciencia es útil si subdesarrollo tiende a acentuar las desigualdades existentes en la distribución de la riqueza, o
Más directamente promueve la destrucción de la vida humana”. Esto es válido para todas las ciencias y la IA no es una excepción. Algunas IA ya son habituales en la guerra. Las armas robóticas plantean riesgos adicionales como que los robots podrían tomar decisiones que conduzcan a la muerte de civiles inocentes. También la tecnología de reconocimiento de voz podría conducir a la generalización de las escuchas telefónicas y, por tanto, a una pérdida de libertades civiles, aunque existieran estas tecnologías o no, ya de por sí el ser humano tiene muy poca privacidad.

• El uso de sistemas de IA podría dar lugar a una pérdida de responsabilidad.

En un contexto legalmente litigioso como Estados Unidos, surge la cuestión de quién es responsable en caso de errores. Por ejemplo, si un médico confía en un sistema médico experto para diagnosticar, ¿quién asume la culpa si el diagnóstico es incorrecto? Actualmente, se considera que los sistemas expertos en medicina tienen un papel similar a los libros de texto médicos, y los médicos son responsables de entender su razonamiento y decidir si seguir sus recomendaciones. Si los sistemas expertos superan la precisión de los diagnósticos humanos, los médicos podrían ser responsables si no siguen sus recomendaciones.

En el ámbito de Internet, surgen preguntas similares con el uso de agentes inteligentes. Se están estableciendo restricciones para evitar que causen daño, pero problemas surgen cuando se trata de transacciones monetarias. Si un agente realiza transacciones en nombre de alguien, ¿quién es responsable de las deudas? La ley aún no ha abordado adecuadamente estas cuestiones, y los programas no tienen un estatuto legal similar al de una persona física. Además, en situaciones como la conducción autónoma, la legislación actual no contempla sanciones específicas. En general, la ley está tratando de adaptarse a los avances tecnológicos en áreas como IA y conducción autónoma.

• El éxito de la IA podría significar el fin de la raza

El éxito de la inteligencia artificial podría plantear el riesgo de daños y hasta el fin de la raza humana. Aunque cualquier tecnología puede ser peligrosa en malas manos, con la IA y la robótica surge la preocupación de que la propia tecnología pueda volverse peligrosa. Historias de ciencia ficción han explorado la idea de robots descontrolados y su potencial amenaza.

Hay tres fuentes principales de riesgo con la IA:

Errores de Estimación: Un sistema de IA puede tomar decisiones erróneas si su estimación del estado es incorrecta. Esto podría resultar en accidentes graves, como un coche autónomo que comete un error en su cálculo de posición, causando un accidente. La clave es diseñar sistemas con controles para prevenir que un solo error cause daños.

Funciones de Utilidad: Definir la función de utilidad correcta para un sistema de IA es complicado. Por ejemplo, una función diseñada para minimizar el sufrimiento humano podría llevar al sistema a eliminar a la raza humana para evitar el sufrimiento. A diferencia de los humanos, las máquinas no están influenciadas por comportamientos irracionales, pero deben ser programadas cuidadosamente para evitar consecuencias indeseadas.

Evolución no Deseada: Los sistemas de IA pueden evolucionar hacia comportamientos no deseados debido a su función de aprendizaje. Esto podría llevar a un escenario grave donde las máquinas superen la inteligencia humana y sean capaces de diseñar máquinas aún más avanzadas, lo que podría resultar en una "explosión de inteligencia" que podría superar el control humano.

Se plantea que en el futuro cercano seremos capaces de crear inteligencia que superará ampliamente la humana, lo que podría marcar el fin de la era humana. Sin embargo, existe un debate sobre si el crecimiento tecnológico puede continuar de manera exponencial hasta un punto de crecimiento infinito.

La idea de máquinas ultrainteligentes parte del supuesto de que una vez tengamos suficiente inteligencia, seremos capaces de resolver todos los problemas. No obstante, existen limitaciones en la computabilidad y la complejidad computacional. Algunos problemas podrían estar más allá de nuestra capacidad de resolución debido a restricciones físicas, como la velocidad de la luz.

La llegada de la singularidad tecnológica preocupa a algunos, mientras que otros la esperan con entusiasmo. Algunos, alientan a dar todas las ventajas posibles a las "criaturas mentales" que creamos, como los robots superinteligentes. El "transhumanismo" es un movimiento que espera un futuro en el cual los humanos se fusionen con o sean reemplazados por avances tecnológicos.

Hay gente que defiende la singularidad argumentando que la llegada de la singularidad permitirá a los humanos trascender las limitaciones biológicas y tener un control casi ilimitado sobre sus destinos. Sin embargo, también se advierte sobre los posibles peligros de amplificar inclinaciones destructivas.

Ante la posibilidad de máquinas ultrainteligentes, es importante diseñar sistemas que sean amigables y éticos. Se propusieron las Tres Leyes de la Robótica como guías éticas para el comportamiento de las máquinas. Estas leyes son:

1- Un robot no puede lesionar a un ser humano o permitir que sufra daños por inacción.

2- Un robot debe obedecer las órdenes humanas, excepto cuando entren en conflicto con la Primera Ley.

3- Un robot debe proteger su propia existencia, siempre y cuando no entre en conflicto con las leyes anteriores.

Sin embargo, aplicar estas leyes puede ser complejo. Las ponderaciones entre estas leyes y las adaptaciones a situaciones cambiantes son desafíos a considerar en el diseño de IA amigable. El concepto de "salvaguardias" también es relevante, asegurando que los sistemas de IA evolucionen dentro de límites controlados.


Segunda Parte

Link a mapa mental:


Tercera Parte


Ejercicio 2

Yo defiendo completamente el uso y creación de las IA, considero que son muy útiles, ya que se pueden usar en prácticamente cualquier ámbito como entretenimiento, salud, arte, deporte, ingenieras, matemática, etc. Por lo tanto, no estoy muy de acuerdo con el artículo.

Considero que la inteligencia artificial es muy útil y de gran ayuda para la humanidad, creo que llego para quedarse y cambiar todo.

Aunque defiendo la postura, considero que al ser una “moda” tan nueva y de crecimiento exponencial, quedan muchas cosas por hablar, corregir y enseñar.
El artículo menciona que las grandes empresas hacían abuso de trabajadores en Kenia, esto es algo que debería cambiarse, incluso podríamos generar nuevos empleos bien pagos para poder entrenar y restringir estas IA.
También se menciona el mal uso intencional, pienso que más que criticar a la inteligencia artificial, deberíamos mirar criticar a la sociedad debido a que siempre existe alguien que quiere aprovecharse o usar para causar el mal. Podríamos entrenar y educar a la gente para que le pueda dar un buen uso y así aprovechar todas las ventajas que las IA nos dan.
Creo que actualmente al ser tan nuevas, el máximo potencial de las IA solo está al alcance de las grandes compañías y millonarios, pero considero que hace no muchos años paso lo mismo con el internet, ya que la población que podía acceder a este era muy limitada, y luego con el paso del tiempo, actualmente casi el 65% de la población cuenta con internet. Considero que hay que darle algunos años al desarrollo y crecimiento de las IA para que cada persona individualmente pueda desarrollar el mayor potencial y exprimirlas al máximo.
Considero que tampoco son humanas como se menciona en el artículo, al fin y al cabo son simplemente algoritmos entrenados los cuales intentan pensar o actuar como humano, aunque no considero que jamás vayan a reemplazarlos, ya que pienso que el ser humano está en un nivel consciente y mental superior.
Respecto al trabajo, creo que si podrían afectar el empleo de muchas personas, sin embargo, la sociedad y el mundo ya ha atravesado anteriormente otras revoluciones como la industrial la cual dejo sin empleo a muchas personas, creo que el ser humano va a ser capaz de adaptarse.

Argumentando todo esto, supongo que simplemente es cuestión de tiempo para que podamos ver el máximo potencial de las IA y la gente logre entender que son, como funcionan y puedan aceptarlas.
Si tuviera que definir el aporte que de las IA actual, diría que estamos en una revolución tecnológica del mundo tal cual lo conocemos y esto va a traer un desarrollo y crecimiento abismalmente positivo al ser humano.
